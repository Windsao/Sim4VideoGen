diff --git a/.gitignore b/.gitignore
index efae7ce..6cc3489 100644
--- a/.gitignore
+++ b/.gitignore
@@ -2,5 +2,4 @@
 test_*
 ./physics_iq_results
 ./phygenbench_results
-wandb
-wandb_logs
\ No newline at end of file
+./wandb/*
diff --git a/data/sim_physics_motion_dataset/metadata.csv b/data/sim_physics_motion_dataset/metadata.csv
index 4e1de68..42138fe 100644
--- a/data/sim_physics_motion_dataset/metadata.csv
+++ b/data/sim_physics_motion_dataset/metadata.csv
@@ -2,21 +2,21 @@ video,prompt,num_frames,num_motion
 test_ball_and_block_fall/env_0/0/0,A physics simulation showing ball and block fall,199,200
 test_ball_collide/env_0/0/0,A physics simulation showing ball collide,199,200
 test_ball_hits_duck/env_0/0/0,A physics simulation showing ball hits duck,199,200
-test_ball_hits_nothing/env_0/0/0,A physics simulation showing ball hits nothing,199,200
+test_ball_hits_nothing/env_0/0/0,A physics simulation showing ball hits nothing,60,60
 test_ball_in_basket/env_0/0/0,A physics simulation showing ball in basket,199,200
 test_ball_ramp/env_0/0/0,A physics simulation showing ball ramp,199,200
 test_ball_rolls_off/env_0/0/0,A physics simulation showing ball rolls off,199,200
 test_ball_rolls_on_glass/env_0/0/0,A physics simulation showing ball rolls on glass,199,200
-test_ball_train/env_0/0/0,A physics simulation showing ball train,199,200
-test_block_domino/env_0/0/0,A physics simulation showing block domino,199,200
+test_block_domino/env_0/0/0,A physics simulation showing block domino,80,80
 test_domino_in_juice/env_0/0/0,A physics simulation showing domino in juice,199,200
-test_domino_with_space/env_0/0/0,A physics simulation showing domino with space,199,200
-test_duck_and_domino/env_0/0/0,A physics simulation showing duck and domino,199,200
+test_domino_with_space/env_0/0/0,A physics simulation showing domino with space,99,100
+test_duck_and_domino/env_0/0/0,A physics simulation showing duck and domino,100,100
 test_duck_falls_in_box/env_0/0/0,A physics simulation showing duck falls in box,199,200
 test_duck_static/env_0/0/0,A physics simulation showing duck static,199,200
 test_light_on_block/env_0/0/0,A physics simulation showing light on block,199,200
 test_light_on_mug_block/env_0/0/0,A physics simulation showing light on mug block,199,200
 test_light_on_mug/env_0/0/0,A physics simulation showing light on mug,199,200
 test_light_on_sculpture/env_0/0/0,A physics simulation showing light on sculpture,199,200
-test_roll_behind_box/env_0/0/0,A physics simulation showing roll behind box,199,200
-test_roll_front_box/env_0/0/0,A physics simulation showing roll front box,199,200
+test_roll_behind_box/env_0/0/0,A physics simulation showing roll behind box,99,100
+test_roll_front_box/env_0/0/0,A physics simulation showing roll front box,99,100
+test_ball_train/env_0/0/0,A physics simulation showing ball train,131,133
diff --git a/train_wan_with_motion.py b/train_wan_with_motion.py
index ccf6302..ece342b 100644
--- a/train_wan_with_motion.py
+++ b/train_wan_with_motion.py
@@ -36,6 +36,7 @@ import argparse
 from typing import Optional, Dict, Any
 from tqdm import tqdm
 
+from safetensors.torch import save_file, load_file
 from diffsynth import load_state_dict
 from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig
 from diffsynth.trainers.utils import DiffusionTrainingModule, ModelLogger, wan_parser
@@ -898,6 +899,26 @@ class MotionAwareWanTrainingModule(DiffusionTrainingModule):
 
         return base_params
 
+    def save_auxiliary_heads(self, output_path: str, step: int = None):
+        """Save motion and depth heads to separate safetensors checkpoint files."""
+        os.makedirs(output_path, exist_ok=True)
+        suffix = f"_step-{step}" if step else ""
+
+        # Save motion head as safetensors if enabled
+        if self.enable_motion and hasattr(self, 'motion_head'):
+            motion_path = os.path.join(output_path, f"motion_head{suffix}.safetensors")
+            # Convert state dict values to contiguous tensors for safetensors
+            motion_state = {k: v.contiguous() for k, v in self.motion_head.state_dict().items()}
+            save_file(motion_state, motion_path)
+            print(f"[INFO] Saved motion head to: {motion_path}")
+
+        # Save depth head as safetensors if enabled
+        if self.enable_depth and hasattr(self, 'depth_head'):
+            depth_path = os.path.join(output_path, f"depth_head{suffix}.safetensors")
+            depth_state = {k: v.contiguous() for k, v in self.depth_head.state_dict().items()}
+            save_file(depth_state, depth_path)
+            print(f"[INFO] Saved depth head to: {depth_path}")
+
 
 class LoadImageSequenceWithMotionWrapper(DataProcessingOperator):
     """
@@ -1154,6 +1175,12 @@ def motion_aware_wan_parser():
         default=10,
         help="Log to wandb every N steps",
     )
+    parser.add_argument(
+        "--save_heads_every_n_steps",
+        type=int,
+        default=100,
+        help="Save motion and depth heads every N steps",
+    )
 
     return parser
 
@@ -1218,6 +1245,7 @@ def launch_training_task_with_wandb(
     # Training loop config
     global_step = 0
     log_every_n_steps = args.log_every_n_steps
+    save_heads_every_n_steps = args.save_heads_every_n_steps
 
     # Initialize wandb on main process only
     if use_wandb and accelerator.is_main_process:
@@ -1371,6 +1399,10 @@ def launch_training_task_with_wandb(
                 # Save checkpoint
                 model_logger.on_step_end(accelerator, model, save_steps)
 
+                # Save auxiliary heads (motion and depth)
+                if accelerator.is_main_process and save_heads_every_n_steps and global_step % save_heads_every_n_steps == 0:
+                    unwrapped_model.save_auxiliary_heads(args.output_path, step=global_step)
+
         # Log epoch summary
         if use_wandb and accelerator.is_main_process:
             epoch_summary = {
@@ -1397,6 +1429,11 @@ def launch_training_task_with_wandb(
     # Final save
     model_logger.on_training_end(accelerator, model, save_steps)
 
+    # Save final auxiliary heads
+    if accelerator.is_main_process:
+        unwrapped_model = accelerator.unwrap_model(model)
+        unwrapped_model.save_auxiliary_heads(args.output_path, step=global_step)
+
     # Finish wandb
     if use_wandb and accelerator.is_main_process:
         wandb.finish()
diff --git a/train_wan_with_motion.sh b/train_wan_with_motion.sh
index 153237d..cf413ff 100755
--- a/train_wan_with_motion.sh
+++ b/train_wan_with_motion.sh
@@ -188,6 +188,12 @@ case "${TRAINING_MODE}" in
         exit 1
         ;;
 esac
+if [ "${USE_WARP_LOSS}" = true ]; then
+    wandb_run_name="${wandb_run_name}_warp_loss"
+fi
+if [ "${USE_SPATIOTEMPORAL_DEPTH}" = true ]; then
+    wandb_run_name="${wandb_run_name}_spatiotemporal_depth"
+fi
 echo ""
 
 # ============================================
@@ -304,8 +310,10 @@ accelerate launch train_wan_with_motion.py \
     --depth_scale ${DEPTH_SCALE} \
     ${SPATIOTEMPORAL_ARGS} \
     ${WARP_ARGS} \
+    --save_heads_every_n_steps 100 \
     --wandb_project "Sim4Videos" \
     --wandb_run_name ${wandb_run_name} \
+    --use_wandb \
 
 
 if [ $? -ne 0 ]; then
@@ -319,11 +327,19 @@ echo "========================================="
 echo "Training complete!"
 echo "========================================="
 echo "Model saved to: ${OUTPUT_MODEL_PATH}"
+echo "  - LoRA weights: ${OUTPUT_MODEL_PATH}/step-XXXX.safetensors"
+echo "  - Motion head: ${OUTPUT_MODEL_PATH}/motion_head_step-XXXX.safetensors"
+echo "  - Depth head: ${OUTPUT_MODEL_PATH}/depth_head_step-XXXX.safetensors"
 echo ""
 echo "To run inference with motion output:"
 echo "  python inference_wan_with_motion.py \\"
 echo "      --lora_checkpoint ${OUTPUT_MODEL_PATH}/step-XXXX.safetensors \\"
+echo "      --motion_head_checkpoint ${OUTPUT_MODEL_PATH}/motion_head_step-XXXX.safetensors \\"
+echo "      --depth_head_checkpoint ${OUTPUT_MODEL_PATH}/depth_head_step-XXXX.safetensors \\"
 echo "      --prompt 'Your prompt here' \\"
 echo "      --output output.mp4 \\"
 echo "      --output_motion motion.npy"
 echo ""
+echo "To continue fine-tuning with train_wan_finetune_all.sh:"
+echo "  ./train_wan_finetune_all.sh ${OUTPUT_MODEL_PATH}"
+echo ""
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 2c1d3c6..3a0dcc1 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20251213_092323-7m9p38p4/logs/debug-internal.log
\ No newline at end of file
+run-20251216_022426-mb2vyzye/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index c8c2902..c1ca74e 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20251213_092323-7m9p38p4/logs/debug.log
\ No newline at end of file
+run-20251216_022426-mb2vyzye/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index 85a75dc..54eff84 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20251213_092323-7m9p38p4
\ No newline at end of file
+run-20251216_022426-mb2vyzye
\ No newline at end of file
